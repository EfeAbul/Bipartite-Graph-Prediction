{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlpWxqw6gm4y"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiJpbX8Igs-A"
      },
      "outputs": [],
      "source": [
        "def generate_erdos_renyi_graphs(n, p, num_graphs):\n",
        "    graphs = []\n",
        "    for i in range(num_graphs):\n",
        "        graphs.append(nx.erdos_renyi_graph(n, p))\n",
        "    return graphs\n",
        "\n",
        "def generate_barabasi_albert_graphs(n, m, num_graphs):\n",
        "    graphs = []\n",
        "    for i in range(num_graphs):\n",
        "        graphs.append(nx.barabasi_albert_graph(n, m))\n",
        "    return graphs\n",
        "\n",
        "def generate_watts_strogatz_graphs(n, k, p, num_graphs):\n",
        "    graphs = []\n",
        "    for i in range(num_graphs): #k yi boris veriyor hukum\n",
        "        graphs.append(nx.watts_strogatz_graph(n, k, p))\n",
        "    return graphs\n",
        "\n",
        "def generate_random_regular_graphs(d, n, num_graphs):\n",
        "    graphs = []\n",
        "    for i in range(num_graphs):\n",
        "        graphs.append(nx.random_regular_graph(d, n))\n",
        "    return graphs\n",
        "\n",
        "def generate_powerlaw_cluster_graphs(n, m, p, num_graphs):\n",
        "    graphs = []\n",
        "    for i in range(num_graphs):\n",
        "        graphs.append(nx.powerlaw_cluster_graph(n, m, p))\n",
        "    return graphs\n",
        "\n",
        "def generate_random_geometric_graphs(n, r, num_graphs):\n",
        "    graphs = []\n",
        "    for i in range(num_graphs):\n",
        "        graphs.append(nx.random_geometric_graph(n, r))\n",
        "    return graphs\n",
        "\n",
        "# Adjacency Matrix\n",
        "def graph_to_adj_matrix(G):\n",
        "    return nx.to_numpy_array(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuUptFsggvJk"
      },
      "outputs": [],
      "source": [
        "# create different types of graphs in a for loop\n",
        "graphs = []\n",
        "\n",
        "num_graphs = 1000\n",
        "\n",
        "n = 100\n",
        "p = 0.0075\n",
        "graphs += generate_erdos_renyi_graphs(n, p, num_graphs)\n",
        "\n",
        "n = 100\n",
        "k = 3\n",
        "p = 0.0001\n",
        "graphs += generate_watts_strogatz_graphs(n, k, p, num_graphs)\n",
        "\n",
        "n = 100\n",
        "m = 2\n",
        "for i in range(num_graphs):\n",
        "  k = random.randint(2, n/2)\n",
        "  p = random.uniform(0.00001, 0.5)\n",
        "  graphs += nx.barabasi_albert_graph(n, m)\n",
        "graphs = generate_watts_strogatz_graphs (100, 4, 0.000000000000001, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVvD1U2VgxW0"
      },
      "outputs": [],
      "source": [
        "connected_graphs = [graph for graph in graphs if nx.is_connected(graph)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r4RMKHH9gzXE"
      },
      "outputs": [],
      "source": [
        "# create a dataframe to store the results\n",
        "df = pd.DataFrame(columns=['graph_type', 'data', 'num_nodes', 'num_edges', 'label'])\n",
        "\n",
        "# calculate the metrics for each graph\n",
        "for graph in connected_graphs:\n",
        "    graph_type = graph.__class__.__name__\n",
        "    data = graph_to_adj_matrix(graph)\n",
        "    num_nodes = graph.number_of_nodes()\n",
        "    num_edges = graph.number_of_edges()\n",
        "\n",
        "    Commenting out the calculations not needed for CNN\n",
        "    avg_degree = np.mean([deg for node, deg in graph.degree()])\n",
        "    avg_clustering_coefficient = nx.average_clustering(graph)\n",
        "    if nx.is_connected(graph):\n",
        "        avg_shortest_path_length = nx.average_shortest_path_length(graph)\n",
        "        avg_eccentricity = np.mean([ecc for node, ecc in nx.eccentricity(graph).items()])\n",
        "        avg_diameter = nx.diameter(graph)\n",
        "        avg_radius = nx.radius(graph)\n",
        "    else:\n",
        "        avg_shortest_path_length = None  # or a default value\n",
        "        avg_eccentricity = None  # or a default value\n",
        "        avg_diameter = None  # or a default value\n",
        "        avg_radius = None  # or a default value\n",
        "    avg_density = nx.density(graph)\n",
        "    avg_closeness_centrality = np.mean([cc for node, cc in nx.closeness_centrality(graph).items()])\n",
        "    avg_betweenness_centrality = np.mean([bc for node, bc in nx.betweenness_centrality(graph).items()])\n",
        "    avg_eigenvector_centrality = np.mean([ec for node, ec in nx.eigenvector_centrality(graph).items()])\n",
        "    avg_pagerank = np.mean([pr for node, pr in nx.pagerank(graph).items()])\n",
        "\n",
        "    try:\n",
        "        partition_first, partition_second = nx.algorithms.community.kernighan_lin_bisection(graph)\n",
        "        graph_first = graph.subgraph(partition_first)\n",
        "        graph_second = graph.subgraph(partition_second)\n",
        "\n",
        "        # Check if the partition divides the graph into nearly equal halves\n",
        "        if abs(len(partition_first) - len(partition_second)) <= 0 and nx.is_connected(graph_first) and nx.is_connected(graph_second):\n",
        "            label = 'Yes'\n",
        "        else:\n",
        "            label = 'No'\n",
        "    except:\n",
        "        print('Error')\n",
        "        pass\n",
        "\n",
        "    # Append only the necessary data for CNN\n",
        "    df.loc[len(df)] = [graph_type, data, num_nodes, num_edges, label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmFh7XF4g20j",
        "outputId": "35d6ea2a-f7b4-4a97-9684-00437ee8cf6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of graphs: 1000\n",
            "Label counts:\n",
            "Yes    703\n",
            "No     297\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the total number of graphs\n",
        "total_graphs = len(df)\n",
        "print(f\"Total number of graphs: {total_graphs}\")\n",
        "\n",
        "# Display the count of each label\n",
        "label_counts = df['label'].value_counts()\n",
        "print(\"Label counts:\")\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaW98vqNg4TZ"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmB7L_vzg5n-"
      },
      "outputs": [],
      "source": [
        "# Step 2: Data Preprocessing\n",
        "\n",
        "# Find the maximum size of the graph (max number of nodes)\n",
        "max_size = max(df['data'].apply(lambda x: x.shape[0]))\n",
        "\n",
        "# Pad the adjacency matrices with zeros\n",
        "X_pre = [np.pad(matrix, ((0, max_size - matrix.shape[0]), (0, max_size - matrix.shape[1])), 'constant') for matrix in df['data']]\n",
        "\n",
        "# Convert to NumPy array\n",
        "X_pre = np.array(X_pre, dtype=np.float32)\n",
        "\n",
        "# Convert labels from 'Yes'/'No' to 1/0\n",
        "y_pre = df['label'].values\n",
        "y = np.array([1 if label == 'Yes' else 0 for label in y_pre])\n",
        "\n",
        "# Now X_pre is your input data\n",
        "X = X_pre\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHnoOtOUg7m6"
      },
      "outputs": [],
      "source": [
        "# Step 3: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_L-_GOgg9NH"
      },
      "outputs": [],
      "source": [
        "# Step 4: Model Architecture\n",
        "model = Sequential()\n",
        "model.add(Reshape((n, n, 1), input_shape=(n, n)))  # Reshape for Conv2D\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5cNS33wg-ZZ"
      },
      "outputs": [],
      "source": [
        "# Step 5: Model Compilation\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CfLhZwDg_4f"
      },
      "outputs": [],
      "source": [
        "# Step 6: Model Training\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni4jM9OPhBf9"
      },
      "outputs": [],
      "source": [
        "# Step 7: Model Evaluation\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}